{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d479e748d66bd09b1b864981f74f2f65b60c2c07",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plot data, visualizations\nimport seaborn as sns #visualization with seaborn\n\nfrom pandas import Series\nfrom sklearn.preprocessing import LabelEncoder #Label Encoding\n#ensemble classifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, BaggingClassifier\n#Classification Algorithm\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold # split data into train and test dataset\nfrom sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score # Model Evaluation\n\nimport sys\nimport os\n#kaggle Data source\nprint(os.listdir(\"../input\"))\n#print(os.listdir(\"D:\\DataScience@DKB\\Classification\")) # Files for analysis",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d49658604818236edee2ddc86c059cf6f4471763"
      },
      "cell_type": "markdown",
      "source": "## Data Preparation and Basic Statistics"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83e5b222f6f37b7a642972cb0a69e58d40ae08e1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#load data and print first 5 rows\ndf = pd.read_csv('../input/lettersdata.csv', index_col=0)\n#df = pd.read_csv('D:\\DataScience@DKB\\Classification\\lettersdata.csv', index_col=0)\nprint(df.head(5))",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de71fdfb67c751b7e868e8c2e72d3513e7c3300c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#show basic statistics\ndf.describe()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "50ae4cd812c42c90bcdbf9ee4685a497272be4af",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#select first two letters of name 'MALI'\n#show data types\ndf.dtypes\n\n#copy data to new df with selected columns\ndf_c = df.loc[df['lettr'].isin(['M','A','L','I'])]\n\nprint(df_c.head(10))\n\n#show data types\nprint(df.dtypes)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0541e5a952bbc7fcd1b523fe262d9d6bb5aa2a9b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#calculate correlations between dimensions\ncor = df_c.corr()\n\n#make correlation heatmap using seaborn lib\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nsns.heatmap(cor,linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\nplt.show()",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f6abec22cf973b2cc01ad4de2146ebf901830d4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X = df_c.drop(['lettr'], axis=1)\nprint(X.head(2))\ny = df_c['lettr']\nprint(y.head(2))\n#set seed value\nseed = 20\n#split data into train and test (and make validation set)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed)\n#X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed)\nprint(X_train.shape)\nprint(X_train.head(2))\nprint(X_test.shape)\nprint(X_test.head(2))\nprint(y_train.head(2))\nprint(y_test.head(2))",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c49985c70d6da7bec762db4a903b3f80795f634c"
      },
      "cell_type": "markdown",
      "source": "## Ensembling: Voting Classifiers"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e85069f1e40bdf2bdf3b17ec32f773dc2127bf3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Ensembling Method: Voting Classifiers (aggregate predictions of each classifier \n#and predict the class that gets the most votes)\nlr_clf = LogisticRegression(random_state=seed)\nrf_clf = RandomForestClassifier(random_state=seed)\nlda_clf = LinearDiscriminantAnalysis()\nsvm_clf = SVC(random_state=seed, probability=True, gamma='auto')\n\nvoting_clf = VotingClassifier(\n            estimators=[('lr', lr_clf),('rf', rf_clf),('lda', lda_clf),('svm',svm_clf)],\n            voting='soft',\n            n_jobs=-1)\nvoting_clf.fit(X_train, y_train)\n\nfor clf in (lr_clf, rf_clf, lda_clf, svm_clf, voting_clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n    #print(confusion_matrix(y_test, y_pred))\n    cm = confusion_matrix(y_test, y_pred)\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\n    classNames = ['M','A','L','I']\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames)\n    plt.yticks(tick_marks, classNames)\n    plt.ylabel('True')\n    plt.xlabel('Predicted')\n    for i in range(4):\n        for j in range(4):\n            plt.text(j, i, str(cm[i][j]))\n    plt.show()",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "47e544f9db211092112d701f9daf68af19be51f2"
      },
      "cell_type": "markdown",
      "source": "## Ensembling: Bagging"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "192023dbbea5d3dbe6a451f31833b81121c16abc",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Ensembling Method: Bagging and Pasting (train the same classifier with different random subsets)\n#of training data (Bagging: sampling with replacement (=bootstrap), Pasting: sampling without replacement)\n\n#Train an ensemble of 500 Desicion Tree classifiers on each subset of 100 instances randomly sampled \n#from the entire training set with replacement (bagging). \n#Parameter n_jobs tells Sklearn the number of CPU cores to use (-1 = use all available cores)  \n#oob_score = Out of Bag (no need for separate validation set), model can be evaluated on oob instances \n\n#standard DecisionTree Classifier\ndt_clf = DecisionTreeClassifier(random_state=seed)\ndt_clf.fit(X_train, y_train)\ny_pred = dt_clf.predict(X_test)\n#print('y_test',y_test, 'y_pred',y_pred)\nprint('DT accuracy: ', str(accuracy_score(y_test, y_pred)))\n\nbag_clf = BaggingClassifier(\n    DecisionTreeClassifier(random_state=seed), n_estimators=500, max_samples=100,\n    bootstrap=True, n_jobs=-1, random_state=seed, oob_score=True)\n#train the model\nbag_clf.fit(X_train, y_train)\ny_pred_bag = bag_clf.predict(X_test)\nprint('Out-of-Bag Score: ', bag_clf.oob_score_)\n\nprint('DT with Bagging accuracy: ', str(accuracy_score(y_test, y_pred_bag)))\n#print(confusion_matrix(y_test, y_pred))\ncm = confusion_matrix(y_test, y_pred)\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\nclassNames = ['M','A','L','I']\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames)\nplt.yticks(tick_marks, classNames)\nplt.ylabel('True')\nplt.xlabel('Predicted')\nfor i in range(4):\n    for j in range(4):\n        plt.text(j, i, str(cm[i][j]))\nplt.show()    ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e877957bb9961071b1817e5ee0c692998e9a8ed"
      },
      "cell_type": "markdown",
      "source": "## Random Forest and Feature Importance"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66584f8a462f64a989a3a84e48f3a918a42aa9f2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#feature importance provided by Random Forest Classifier measures the importance of different \n#features by looking at how much the tree nodes that use that feature reduce impurity\n#on average\n\nfeature_list = []\nscore_list = []\n\nrf_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\nrf_clf.fit(X_train, y_train)\nfor feature, score in zip(list(X_train), rf_clf.feature_importances_):\n    #print(feature, score)\n    feature_list.append(feature)\n    score_list.append(score)\n    \n#print(feature_list)\n#print(score_list)\n\nplt.figure(figsize=(14,6))\nplt.title(\"Feature Importance\")\nplt.ylabel('feature_importance')\nplt.xlabel('feature')\nx = feature_list\nplt.bar(x, score_list)\n\nplt.show()",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f54327a66750c7019178d28dafb74760481cb4fc"
      },
      "cell_type": "markdown",
      "source": "## Ensembling: Boosting"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38ca9a9097202379b6d208142401d58fd3f40e48",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Ada Boost (Adaptive Boosting) \n#First base classifier is trained and used to make predictions on the training set.\n#The relative weight of misclassified training instances is then increased. \n#The second classifier is trained using the updated weights and again it makes predictions\n#on the training set (sequential training (learning)).\n#SAMME.R (Stagewise Additive Modeling using Multiclass Exp. Loss function)\n#R = Real, using class_probabilities (if provided by classifier)\n\nada_clf = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=2), n_estimators=200, \n    algorithm='SAMME.R', learning_rate=0.01)\nada_clf.fit(X_train, y_train)\ny_pred = ada_clf.predict(X_test)\nprint('ADA accuracy: ', str(accuracy_score(y_test, y_pred)))\n\ncm = confusion_matrix(y_test, y_pred)\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\nclassNames = ['M','A','L','I']\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames)\nplt.yticks(tick_marks, classNames)\nplt.ylabel('True')\nplt.xlabel('Predicted')\nfor i in range(4):\n    for j in range(4):\n        plt.text(j, i, str(cm[i][j]))\nplt.show()    \n",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17acd173edc9948848b547b0ec8f9d27c9287a67",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Gradient Boosting\n#sequentially adding predictors to an ensemble, each on correcting its predecessor\n#tries to fit the new predictor to the residual errors made by the previous predictor\n\ngb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=1.0)\ngb_clf.fit(X_train, y_train)\ny_pred = gb_clf.predict(X_test)\n#print(y_pred)\nprint('GB accuracy: ', str(accuracy_score(y_test, y_pred)))\n\ncm = confusion_matrix(y_test, y_pred)\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\nclassNames = ['M','A','L','I']\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames)\nplt.yticks(tick_marks, classNames)\nplt.ylabel('True')\nplt.xlabel('Predicted')\nfor i in range(4):\n    for j in range(4):\n        plt.text(j, i, str(cm[i][j]))\nplt.show() ",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "54282f273dbcea61cbf41df8d2cbdc4fe6f32481"
      },
      "cell_type": "markdown",
      "source": "## Ensembling: Stacking"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23f9c0a857db8b45ffe587b5cfa2d9fe41f25223",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Stacking (stacked generalization): train several models and make predictions on subsets (folds)\n#of the training data. Take the predictions as a new training set for the next (or final) layer (model/classifier)\n#Use hold-out sets (folds) to ensure the predictors never saw the instances during training.\n\n#Build Method to make predictions on stratiefied n-folds (preserving the percentage of samples for each class)\n\nprint(X_train.head(5))\nprint((X_train.shape[0],1))\nprint(X_test.head(5))\nprint((X_test.shape[0],1))\nprint(y_train.head(5))\n\ndef Stacking(model,X_train,y_train,X_test,kfold):\n    \n    kf=StratifiedKFold(n_splits=kfold,random_state=seed)\n    test_pred=np.empty((0,1))\n    train_pred=np.empty((0,1))\n    \n    for train_index,test_index in kf.split(X_train,y_train.values):\n        \n        x_tr,y_tr=X_train.iloc[train_index],y_train.iloc[train_index] \n        x_te,y_te=X_train.iloc[test_index],y_train.iloc[test_index]\n        \n        #print('x_tr', x_tr.head(5))\n        #print('x_val', x_val.head(5))\n        #print('y_tr', y_tr.head(5))\n        #print('y_val', y_val.head(5))\n\n        model.fit(X=X_train,y=y_train)\n        \n        le = LabelEncoder()\n              \n        train_pred=np.append(train_pred,model.predict(x_te))\n        test_pred=np.append(test_pred,model.predict(X_test))\n                       \n    return test_pred.reshape(-1,1), train_pred\n",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "975406e10ba49fe1b1a2817f4fedc12548b5b33e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train the base model: Random Forest   , Ada Boost, Logistic Regression)\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=seed)\n\n#use Stacking Method to train the model\ntest_pred_rf, train_pred_rf = Stacking(model=rf, X_train=X_train, X_test=X_test, y_train=y_train, kfold=4)\n\n#write results to new data frame and encode labels for second layer classification algo\nle = LabelEncoder()\ntrain_pred_rf = pd.DataFrame(le.fit_transform(train_pred_rf))\ntest_pred_rf = pd.DataFrame(le.fit_transform(test_pred_rf))\n\n\nprint(train_pred_rf.shape)\nprint(test_pred_rf.shape)\nprint(train_pred_rf.head(5))\nprint(test_pred_rf.head(5))\n\n",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4d788a701c843ba780f1a7ddaa564dc9e85f58e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train the base model: Ada Boost\nada = AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=seed)\n\n#use Stacking Method to train the model\ntest_pred_ada, train_pred_ada = Stacking(model=ada, X_train=X_train, X_test=X_test, y_train=y_train, kfold=4)\n\n#write results to new data frame and encode labels for second layer classification algo\nle = LabelEncoder()\ntrain_pred_ada = pd.DataFrame(le.fit_transform(train_pred_ada))\ntest_pred_ada = pd.DataFrame(le.fit_transform(test_pred_ada))\n\nprint(train_pred_ada.shape)\nprint(test_pred_ada.shape)\n",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bba7108eba619bdea8b1848de1686518357821f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train the base model: Logistic Regression\nlr = LogisticRegression(random_state=seed)\n\n#use Stacking Method to train the model\ntest_pred_lr, train_pred_lr = Stacking(model=lr, X_train=X_train, X_test=X_test, y_train=y_train, kfold=4)\n\n#write results to new data frame and encode labels for second layer classification algo\nle = LabelEncoder()\ntrain_pred_lr = pd.DataFrame(le.fit_transform(train_pred_lr))\ntest_pred_lr = pd.DataFrame(le.fit_transform(test_pred_lr))\n\nprint(train_pred_lr.shape)\nprint(test_pred_lr.shape)\n",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "188d121a3c19607e5895cec841c1e9ce7febd403",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Combine the predictions from the first layer in one data frame as new training set \n#for the second layer (sl)\n\nX_train_sl = pd.concat([train_pred_rf, train_pred_ada, train_pred_lr], axis=1)\nX_test_sl = pd.concat([test_pred_rf, test_pred_ada, test_pred_lr], axis=1)\n\nX_train_sl.columns = ['rf','ada','lr']\nX_test_sl.columns = ['rf','ada','lr']\n\nprint(X_train_sl.head(5))\nprint(X_test_sl.head(5))\n\nprint(X_train_sl.shape)\nprint('Issue', X_test_sl.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)\n\n",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "511812fd726e80925939d5c57bd57e28bab2b265",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Second Layer Model (Gradient Boosting) using predictions from the first layer\n\nlrm = LogisticRegression(random_state=seed)\n#gbm = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=1.0)\n#lrm.fit(X_train_sl, y_train)\n#lrm.score(X_test_sl, y_test)\n",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b8df878766aa03010ae9fe2d107ca9c0e9bd42df"
      },
      "cell_type": "markdown",
      "source": "****## Ensembling: Blending (Stacking)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f01de4b3836a510f554fe62f12bbc4354e2c8052",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#split data into train and test (and make validation set)\nX_train_val1, X_test1, y_train_val1, y_test1 = train_test_split(X, y, test_size=0.25, random_state=seed)\nX_train1, X_val1, y_train1, y_val1 = train_test_split(X_train_val1, y_train_val1, test_size=0.25, random_state=seed)\nprint('X_train1: ', X_train1.shape)\nprint('X_test1: ', X_test1.shape)\nprint('X_train_val1: ', X_train_val1.shape)\nprint('X_val1: ', X_val1.shape)\nprint('y_train1: ', y_train1.shape)\nprint('y_test1: ', y_test1.shape)\nprint('y_train_val1: ', y_train_val1.shape)\nprint('y_val1: ', y_val1.shape)\n\n",
      "execution_count": 72,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d0ad33642f9a3e4e77f2609f198b59ce20b5d9f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#initialize base models\nlr1_clf = LogisticRegression(random_state=seed)\ndt1_clf = DecisionTreeClassifier(random_state=seed)\nlda1_clf = LinearDiscriminantAnalysis()\nada1_clf = AdaBoostClassifier(random_state=seed)\ngbm1_clf = GradientBoostingClassifier(random_state=seed)\nsvc1_clf = SVC(random_state=seed, gamma='auto')\nrf1_clf = RandomForestClassifier(random_state=seed)\nextr1_clf = ExtraTreesClassifier(random_state=seed)\n",
      "execution_count": 73,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b744a93127f5c4a60c65f1e6ee5c7d971be800c5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Train the first layer models\nmodels = [lr1_clf, dt1_clf, lda1_clf, ada1_clf, gbm1_clf, svc1_clf, rf1_clf, extr1_clf]\nfor model in models:\n    print(\"Training the\", model)\n    model.fit(X_train1, y_train1)",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94dfa46fb180a010145b57711dfd794a96bbf716",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#show model scores\n[model.score(X_val1, y_val1) for model in models]\n\n",
      "execution_count": 75,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36d8177a4c6d337702f482523f5613bc1987b986",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#save X_val predictions for the second layer model\nX_val_predictions = np.empty((len(X_val1), len(models)), dtype=np.float32)\n\nfor index, model in enumerate(models):\n    X_val_predictions[:, index] = le.fit_transform(model.predict(X_val1))\n    \nprint('Label Encoded Predictions', X_val_predictions)\n\n#transform to pd Dataframe to show correlations between model predictions on validation set\npd_corr =  pd.DataFrame(data=X_val_predictions[:,:],   \n                        columns=X_val_predictions[0,:])\npd_corr.columns = ['lr','dt','lda','ada','gbm','svc','rf','extr']\nprint(pd_corr.head(5))\n\n#calculate correlations between models\ncor = pd_corr.corr()\n\n#make correlation heatmap using seaborn lib\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(10,8))\nsns.heatmap(cor,linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()\n    ",
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0dbf3c9ee1f125554880521dd6909cd31fef1596",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train the second layer  model\nrf_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=seed)\nrf_blender.fit(X_val_predictions, y_val1)\n\nprint(rf_blender.oob_score_)\n\n",
      "execution_count": 77,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7766f20ed68fdfa2665295f24aba8fdb5fc95ef4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#save X_test predictions\n\nX_test_predictions = np.empty((len(X_test1), len(models)), dtype=np.float32)\n\nfor i, model in enumerate(models):\n    X_test_predictions[:, i] = le.fit_transform(model.predict(X_test1))\n\ny_pred1 = rf_blender.predict(X_test_predictions)\n\nprint(accuracy_score(y_test1, y_pred1))\n\ncm = confusion_matrix(y_test1, y_pred1)\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\nclassNames = ['M','A','L','I']\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames)\nplt.yticks(tick_marks, classNames)\nplt.ylabel('True')\nplt.xlabel('Predicted')\nfor i in range(4):\n    for j in range(4):\n        plt.text(j, i, str(cm[i][j]))\nplt.show() \n\n",
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f5273f648f4f84b03e8a3817fd530b8bfc764b86"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}